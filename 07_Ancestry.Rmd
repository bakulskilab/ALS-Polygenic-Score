---
title: "07_ancestry"
author: "John Dou"
date: "January 20, 2021"
output: html_document
---

```{batch}
module load Bioinformatics
module load plink/1.9
module load R

cd /nfs/turbo/bakulski1/People/johndou/ALS_Goutman/07_Ancestry/
```


## merge with 1000 genomes

```{batch}
# Extract the variants present in als dataset from the 1000 genomes dataset.

awk '{print$2}' ../06_Relate/als10_PAR_rel.bim > als_SNPs.txt
plink --bfile /nfs/turbo/bakulski1/People/johndou/ALS/07_ancestry/1000G_QC/1000G_maf --extract als_SNPs.txt --allow-extra-chr --make-bed --out 1000G_snp_match



# Extract the variants present in 1000 Genomes dataset from the als dataset.

awk '{print$2}' /nfs/turbo/bakulski1/People/johndou/ALS/07_ancestry/1000G_QC/1000G_maf.bim > 1000G_snps.txt
plink --bfile ../06_Relate/als10_PAR_rel --extract 1000G_snps.txt --recode --make-bed --out als_snp_match



# The datasets must have the same build. Change the build to 1000 Genomes data build.

awk '{print$2,$4}' als_snp_match.map > build.txt
plink --bfile 1000G_snp_match --update-map build.txt --make-bed --out 1000G_snp_match_build



# 1) set reference genome 
awk '{print$2,$5}' 1000G_snp_match_build.bim > 1000G_ref_list.txt
plink --bfile als_snp_match --reference-allele 1000G_ref_list.txt --make-bed --out als_ref_match


### genome harmonizer
java -Xms16g -jar /nfs/turbo/bakulski1/Software/GenotypeHarmonizer-1.4.23/GenotypeHarmonizer.jar \
  --input als_snp_match\
  --output als_genome_harmonize\
  --ref 1000G_snp_match_build

plink --file als_genome_harmonize --make-bed --out als_genome_harmonize

# 2) Resolve strand issues.
# Check for potential strand issues.
awk '{print$2,$5,$6}' 1000G_snp_match_build.bim > 1000G_tmp
awk '{print$2,$5,$6}' als_genome_harmonize.bim > als_tmp
sort 1000G_tmp als_tmp |uniq -u > all_differences.txt

## Flip SNPs for resolving strand issues.
# Print SNP-identifier and remove duplicates.
awk '{print$1}' all_differences.txt | sort -u > flip_list.txt
plink --bfile als_genome_harmonize --flip flip_list.txt --reference-allele 1000G_ref_list.txt --make-bed --out corrected_als

# Check for SNPs which are still problematic after they have been flipped.
awk '{print$2,$5,$6}' corrected_als.bim > corrected_als_tmp
sort 1000G_tmp corrected_als_tmp |uniq -u  > uncorresponding_SNPs.txt



# 3) Remove problematic SNPs from als data and 1000 Genomes.
awk '{print$1}' uncorresponding_SNPs.txt | sort -u > SNPs_for_exlusion.txt

# Remove the remaining problematic SNPs from both datasets.
plink --bfile corrected_als --exclude SNPs_for_exlusion.txt --make-bed --out als_ready_for_merge
plink --bfile 1000G_snp_match_build --exclude SNPs_for_exlusion.txt --make-bed --out 1000G_ready_for_merge

# Merge als data with 1000 Genomes Data.
plink --bfile als_ready_for_merge --bmerge 1000G_ready_for_merge.bed 1000G_ready_for_merge.bim 1000G_ready_for_merge.fam --allow-no-sex --make-bed --out als_1000G_merge



## Perform MDS 
# Using a set of pruned SNPs
plink --bfile als_1000G_merge --extract ../05_Heterozygosity/indepSNP.prune.in --genome --out ./MDS/merge
plink --bfile als_1000G_merge --read-genome ./MDS/merge.genome --cluster --mds-plot 10 --out ./MDS/merge_mds

```


```{r}
# tg_pop <- read.table("/scratch/png_project_root/png_project1/shared_data/1000genomes/ancestrydat/1000gene_pops.txt")
# colnames(tg_pop) <- c('id','sex','superpop','pop')
# saveRDS(tg_pop, file='tg_pop.RDA')
tg_pop <- readRDS('tg_pop.RDA')

library(openxlsx)
library(scales)
als_pop <- read.xlsx("../pd.xlsx")
als_pop <- als_pop[,c(1,6,7)]
colnames(als_pop) <- c('id','superpop','ethnicity')
als_pop$superpop <- 
      ifelse(als_pop$superpop %in% c("caucasian", "white"), "WHITE OR CAUCASIAN",
      ifelse(als_pop$superpop %in% c("black/african american"), "BLACK OR AFRICAN AMERICAN",
      ifelse(als_pop$superpop=="other asian", "ASIAN", als_pop$superpop)))
als_pop$superpop <- 
      ifelse(als_pop$ethnicity=="Hispanic or Latino", "HISPANIC OR LATINO", als_pop$superpop)
als_pop <- als_pop[,c(1,2)]

#get genetic ids, make sure it matches
als_ids <- read.table("als_snp_match.fam")
table(als_ids$V2 %in% als_pop$id)
# FALSE  TRUE
#   349   141
als_pop$id <- as.numeric(als_pop$id)
table(als_ids$V2 %in% als_pop$id)
# FALSE  TRUE
#     3   487
als_ids$V2[!als_ids$V2 %in% als_pop$id]
# _0086 3968  8990
table(als_pop$id %in% als_ids$V2)
als_pop$id[!als_pop$id %in% als_ids$V2]
als_pop$id <- ifelse(als_pop$id==86, '_0086',als_pop$id)
table(als_ids$V2 %in% als_pop$id)
# FALSE  TRUE
#     2   488

tg_pop_m <- tg_pop[,c(1,3)]
pop_m <- rbind(tg_pop_m,als_pop)

data <- read.table(file="MDS/merge_mds.mds",header=TRUE)
mds <- merge(data, pop_m, by.x="IID", by.y="id")

mds$col <- ifelse(mds$superpop=='AFR', 'darkolivegreen1', 
			ifelse(mds$superpop=='AMR', 'coral',
			ifelse(mds$superpop=='EAS', 'paleturquoise',
			ifelse(mds$superpop=='EUR', 'indianred1',
			ifelse(mds$superpop=='SAS', 'orchid1',
			ifelse(mds$superpop=='WHITE OR CAUCASIAN', 'firebrick2',
			ifelse(mds$superpop=='BLACK OR AFRICAN AMERICAN', 'darkgreen',
			ifelse(mds$superpop=='ASIAN', 'lightblue3',
			ifelse(mds$superpop=='HISPANIC OR LATINO', 'coral', 'gray11')))))))))
mds$col <- ifelse(is.na(mds$col),'gray11',mds$col)

col_ref <- unique(mds[,c('superpop','col')])
col_ref_tg <- col_ref[6:10,]
col_ref_als <- col_ref[1:5,]

pdf('MDS/MDS.pdf')
  mds_tg <- mds[mds$IID %in% tg_pop$id,]
  mds_als <- mds[!mds$IID %in% tg_pop$id,]
  #mds_als$superpop <- relevel(factor(mds_als$superpop), ref="WHITE OR CAUCASIAN")
  #mds_als <- mds_als[order(mds_als$superpop),]
  
  plot(mds_tg$C1, mds_tg$C2, col=alpha(mds_tg$col,0.4), ylim=c(-0.06, 0.06), pch=15)
  points(mds_als$C1, mds_als$C2, col=mds_als$col)
  legend('bottomright', title='1000 genomes groups', legend=col_ref_tg$superpop, fill=col_ref_tg$col)
  legend('topright', title='ALS groups', legend=col_ref_als$superpop, fill=col_ref_als$col)
dev.off()


setwd('/nfs/turbo/bakulski1/People/johndou/ALS/')
write.csv(mds_als$IID, file='samples_passing_QC.csv', quote=F)

mds[mds$superpop!='WHITE OR CAUCASIAN' & grepl('FELD',mds$IID),]

keep <- mds_als[mds_als$IID=='FELD337' | mds_als$superpop=='WHITE OR CAUCASIAN',]
keep <- keep[!keep$V1 %in% c('FELD394','FELD494'),]
write.table(keep[,1:2], file='/nfs/turbo/bakulski1/People/johndou/ALS/keep_euro.txt', quote=F, row.names=F, col.names=F)
```